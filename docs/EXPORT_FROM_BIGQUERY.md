# ðŸ“¥ GuÃ­a RÃ¡pida: Exportar desde BigQuery UI

## ðŸŽ¯ Pasos para Exportar la Tabla

### 1. En la Interfaz de BigQuery que tienes abierta:

**OpciÃ³n A: Exportar Directamente (Recomendado para tablas pequeÃ±as < 1GB)**

1. Haz click en la tabla `BBDDTINSA_PYTO_CENTROcsv_1770655119181`
2. Click en el botÃ³n **"EXPORTAR"** (arriba a la derecha)
3. Selecciona **"Exportar a CSV"**
4. Elige:
   - **Formato**: CSV
   - **CompresiÃ³n**: Ninguna (o GZIP si es muy grande)
   - **UbicaciÃ³n**: Descarga local
5. Click en **"Exportar"**
6. Espera a que se descargue

**OpciÃ³n B: Query y Exportar (Para mÃ¡s control)**

1. Click en **"CONSULTAR"** (botÃ³n azul)
2. En el editor SQL, escribe:
   ```sql
   SELECT * FROM `my-project-wap-486916.BBDDTINSATables.BBDDTINSA_PYTO_CENTROcsv_1770655119181`
   ```
3. Click en **"EJECUTAR"**
4. Cuando termine, click en **"GUARDAR RESULTADOS"**
5. Selecciona **"CSV (local)"**
6. Descarga el archivo

### 2. Guardar el Archivo

Una vez descargado:

```bash
# Mueve el archivo descargado a:
mv ~/Downloads/BBDDTINSA_PYTO_CENTROcsv_*.csv \
   ~/REPOS/mercado-Inmobiliario/backend/data/tinsa_export.csv
```

O manualmente:
1. Abre Finder
2. Ve a `Descargas`
3. Encuentra el archivo CSV descargado
4. CÃ³pialo a: `REPOS/mercado-Inmobiliario/backend/data/tinsa_export.csv`

### 3. Verificar el Archivo

```bash
cd ~/REPOS/mercado-Inmobiliario/backend

# Ver las primeras lÃ­neas
head -5 data/tinsa_export.csv

# Contar filas
wc -l data/tinsa_export.csv
```

### 4. Previsualizar los Datos

```bash
.venv/bin/python -m app.etl.csv_to_supabase --preview
```

Esto mostrarÃ¡:
- âœ… Todas las columnas del CSV
- âœ… Primeras 20 filas
- âœ… Total de registros

### 5. Ajustar el Mapeo

Edita el archivo: `backend/app/etl/csv_to_supabase.py`

En la funciÃ³n `map_tinsa_to_supabase()`, reemplaza los nombres de ejemplo con los nombres reales que viste en el preview:

```python
# Ejemplo: Si tu CSV tiene una columna llamada "Nombre_Proyecto"
"name": str(row.get("Nombre_Proyecto", f"Proyecto {idx}")),

# Si tiene "Comuna"
"commune": str(row.get("Comuna", None)),

# Si tiene "Precio_UF"
"avg_price_uf": float(row.get("Precio_UF", None)),
```

### 6. Ejecutar Dry-Run

```bash
.venv/bin/python -m app.etl.csv_to_supabase
```

Verifica que el mapeo sea correcto.

### 7. MigraciÃ³n Real

```bash
.venv/bin/python -m app.etl.csv_to_supabase --migrate
```

---

## ðŸš¨ Si la Tabla es Muy Grande (> 1GB)

BigQuery no permite descargas directas de tablas muy grandes. En ese caso:

### OpciÃ³n 1: Exportar a Google Cloud Storage

1. En BigQuery, click en **"EXPORTAR"**
2. Selecciona **"Exportar a GCS"**
3. Formato: CSV
4. URI: `gs://tu-bucket/tinsa_export_*.csv`
5. Luego descarga desde Cloud Storage Console

### OpciÃ³n 2: Exportar por Partes

```sql
-- Exportar por comunas
SELECT * FROM `my-project-wap-486916.BBDDTINSATables.BBDDTINSA_PYTO_CENTROcsv_1770655119181`
WHERE comuna = 'Las Condes'
```

Ejecuta varias queries y exporta cada una.

---

## ðŸ“Š Verificar Datos Importados

Una vez completada la migraciÃ³n:

```bash
# Conectar a Supabase y verificar
psql "postgresql://postgres:[password]@db.dbnkdfedcsxtwtzrrfld.supabase.co:5432/postgres"

# O usar el SQL Editor en Supabase Dashboard
SELECT COUNT(*) FROM projects;
SELECT * FROM projects LIMIT 10;
```

O visita:
- http://localhost:3000/dashboard/projects
- http://localhost:3000/dashboard/map

---

## ðŸ†˜ Problemas Comunes

### "No se puede exportar: tabla muy grande"
â†’ Usa exportaciÃ³n a GCS o exporta por partes

### "Error de encoding al leer CSV"
â†’ El script prueba automÃ¡ticamente UTF-8, Latin-1, ISO-8859-1

### "Columna no encontrada"
â†’ Revisa el preview y ajusta los nombres en `map_tinsa_to_supabase()`

### "Duplicate key error"
â†’ Normal, el script usa `upsert` y actualiza duplicados
